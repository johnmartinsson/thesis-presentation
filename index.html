<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="css/custom.css">
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/solarized.css" id="theme">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-markdown>
          <script type="text/template">
            ## Bird Species Identification using Convolutional Neural Networks
          </script>
        </section>
				<section data-markdown>
          <script type="text/template">
            ## Summary

            - Introduction
            - Problem Formulation
            - Aim and Questions
            - Methods
            - Results
            - Discussion
            - Conclusions
          </script>
        </section>
        <section>
          <h3> Manual Point Count </h3>
          <img src="images/GuyPointCount.svg" height="50%" width ="50%">
          <aside class="notes">
            <ul>
              <li> Requires expertise </li>
              <li> Time consuming </li>
              <li> Consistency is a necessity </li>
            </ul>
          </aside>
        </section>
        <section>
          <h3> Point Count Data </h3>
          <img src="images/PointCount.svg" height="40%" width ="40%">
        </section>
        <section>
          <h3> Automatic Point Count </h3>
          <img src="images/GuyPointCountMic.svg" height="50%" width ="50%">
          <p class="fragment" data-audio-src="audio/bird1.ogg">
            Listen to birds
          </p>
          <p class="fragment" data-audio-src="audio/bird2.ogg">
          </p>
          <p class="fragment" data-audio-src="audio/bird3.ogg">
          </p>
          <aside class="notes">
            <ul>
              <li> Consistent and less biased </li>
              <li> Requires no expertise </li>
              <li> Can be paced for continuous monitoring </li>
            </ul>
          </aside>
        </section>
				<section data-markdown data-separator="^\n\n\n" data-separator-vertical="^\n\n" data-separator-notes="^Note:">
          <script type="text/template">
            ## Why birds and why is this important?
            - Birds are easy to observe
            - Indicators of ecosystem health
            - Grounds for conservation effors
            - Understand population health

            Note:
            - Pollinate
            - Disperse seeds
            - Pest control.
          </script>
        </section>
        <section>
          <section data-markdown>
            <script type="text/template">
              ## Problem formulation

              - Signal Classification
              - Feature Extraction

            </script>
          </section>
          <section>
            <h2> Signal Classification </h2>
            <div>
              \[ X = \{(y_i, x_i)\}, i=1, \dots, N \]
            </div>
            <div class="equation">
            \[ w = \arg\min_{w} \sum_{(y, x) \in X} loss(f(x), f_w(x)) \]
            </div>
          </section>
          <section>
            <h2> Feature Extraction </h2>
            <ul>
              <li> Reduce the size of the input </li>
              <li> Trade-off between separability and contraction </li>
            </ul>
            <div class="equation">
              \[ \text{if } \Phi(x) \neq \Phi(x') \text{ then } f(x) \neq f(x') \]
            </div>
          </section>
          <section>
            <h2> Feature Extraction </h2>
            <div>
              \[
              \begin{aligned}
              \text{if } &amp; \Phi((x, y)) = x \text{ and } f((x, y)) = y \\
              \text{ then } &amp; \Phi((1, 3)) \neq \Phi(2, 3) \\
              \text{ but } &amp; f((1, 3)) = f((2, 3))
              \end{aligned}
              \]
            </div>
          </section>

        </section>
        <section>
          <h2> Aim & Questions </h2>
          <ul>
            <li class="fragment"> Aim: Improve upon the state-of-the-art </li>
            <li class="fragment">
              Can deep residual neural networks learn to classify bird
              species based on audio recordings, and how well do they perform?
            </li>
            <li class="fragment">
              Can multiple-width frequency-delta data augmentation be used to
              improve how well the model generalizes?
            </li>
            <li class="fragment">
              Can meta-data fusion be used to improve the classification
              accuracy of the model?
            </li>
          </ul>
          <aside class="notes">
            <ul>
              <li> Answered by training on a large data set </li>
              <li> Evaluating on a large test set </li>
              <li> Compare results with baseline </li>
            </ul>
          </aside>
        </section>
        <section data-markdown>
          <script type="text/template">
            ## Data set
            - BirdCLEF 2016
            - 24,600 training files
            - 8,600 test files
            - 999 different bird species
            - Field recordings
            - Can contain background species
          </script>
        </section>
        <section>
          <section data-markdown>
            <script type="text/template">
              ## Baseline
              - Preprocessing
              - Data augmentation
              - Feature extraction
              - Signal classification
            </script>
          </section>
          <section>
            <h4> Detect Structure </h4>
            <img src="images/sprengel_binary_mask.png" height="40%" width ="40%">
          </section>
          <section>
            <h4> Separate Signal and Noise </h4>
            <img src="images/noise_signal.png" height="50%" width ="50%">
          </section>
          <section data-markdown>
            <script type="text/template">
              ## Data Augmentation
              - Same class
              - Noise
              - Time shift
              - Pitch shift
            </script>
          </section>
          <section>
            <h2> Same Class Augmentation </h2>
            <img src="images/same_class_augmentation.png" height="50%" width ="50%">
          </section>
          <section>
            <h2> Noise Augmentation </h2>
            <img src="images/noise_augmentation.png" height="50%" width ="50%">
            <aside class="notes">
              <ul>
                <li> Add three noise segments </li>
                <li> Harder to classify </li>
                <li> Noise invariant, Generalization </li>
              </ul>
            </aside>
          </section>
          <section>
            <h2> Feature Extraction </h2>
            <p> Logarithmic spectrogram </p>
            <img src="images/logspectrogram.png" height="50%" width="50%">
            <aside class="notes">
              <ul>
                <li> Data augmentation in time domain </li>
                <li> Time-spectral representation </li>
              </ul>
            </aside>
          </section>
          <section data-markdown data-separator="^\n\n\n" data-separator-vertical="^\n\n" data-separator-notes="^Note:">
            <script type="text/template">
              ## Convolutional neural network
              - 5x BatchNormalization, Convolution2D, MaxPooling2D
              - BatchNormalization
              - Flatten
              - Dropout (40%)
              - Dense (1024 neurons)
              - Dropout (40%)
              - Dense (999 neurons)

              Note:
              - Bach normalization reduces the risk of vanishing/exploding
              gradients/signals
              - Convolving layers learns feature extraction mappings
              - Max pooling reduces the size of the features
              - Fully connected network learns to classify the extracted
              features.
            </script>
          </section>
        </section>
        <section>
          <section data-markdown>
            <script type="text/template">
              ## Methods

              - Deep residual neural networks
              - Multiple-width frequency-delta data augmentation
              - Meta-data fusion
            </script>
          </section>
          <section>
            <h2> Deep residual neural networks </h2>
            <ul>
              <li> Introduce shortcuts </li>
              <li> Allow training of very deep networks </li>
            </ul>
          </section>
          <section>
            <h2> Shortcut </h2>
            <img src="images/residual-function.png" height="50%" width ="50%">
            <div class="fragment">
              \[ y = \mathcal{H}(x) = \mathcal{F}(x) + x \]
            </div>
            <aside class="notes">
              <ul>
                <li> Closer to itentity mapping </li>
              </ul>
            </aside>
          </section>
          <section>
            <h2> Multiple-width frequency-delta data augmentation </h2>
            <ul>
              <li> Mel-frequency cepstral coefficients (MFCCs) </li>
              <li> Deltas of MFCCs </li>
              <li> Input: \[ (MFCCs, \Delta3, \Delta11, \Delta19) \] </li>
            </ul>
          </section>
          <section>
            <h2> Meta-data fusion </h2>
            <div>
              \[
              Pr(bird_i|elevation, song) = \\
              \frac{Pr(bird_j|song)Pr(elevation|bird_j)}
              {\sum_{i=1}^n Pr(bird_i|song)Pr(elevation|bird_i)}
              \]
            </div>
            <aside class="notes">
              <ul>
                <li> Assumption: Pr(elevation|song,bird) = Pr(elevation|bird) </li>
              </ul>
            </aside>
          </section>
        </section>
        <section>
          <section data-markdown>
            <script type="text/template">
              ## Results

              - Deep residual neural networks
              - Meta-data fusion
            </script>
          </section>
          <section data-markdown>
            <script type="text/template">
              ## Deep residual neural networks
              | Method | MAP (with) | MAP (without) |
              | --- | --- | --- |
              | Baseline | 55.8% | 69.7% |
              | Resnet 18 | 53.8% | 67.9% |
            </script>
          </section>
          <section data-markdown data-separator="^\n\n\n" data-separator-vertical="^\n\n" data-separator-notes="^Note:">
            <script type="text/template">
              ## Meta-data fusion
              - Reduce coverage error by ~4
              - MAP score is barely affected

              Note:
              - Ground truth labels are on average predicted higher
              - Not high enough to affect the MAP score
            </script>
          </section>
        </section>
        <section>
          <section data-markdown>
            <script type="text/template">
              ## Discussion
            </script>
          </section>
        </section>
			</div>
		</div>
		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				history: true,
        audio : {
          defaultDuration: 600
        },

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/menu/menu.js' },
					{ src: 'plugin/math/math.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
          { src: 'plugin/audio-slideshow/slideshow-recorder.js', condition: function( ) { return !!document.body.classList; } },
          { src: 'plugin/audio-slideshow/audio-slideshow.js', condition: function( ) { return !!document.body.classList; } }
				]
			});
		</script>
	</body>
</html>
